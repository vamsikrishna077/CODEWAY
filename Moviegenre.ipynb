{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsikrishna077/CODEWAY/blob/main/Moviegenre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W3GNcg7IMwGo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer,PorterStemmer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuth65OleRll"
      },
      "outputs": [],
      "source": [
        "!unzip archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLoA376ZQ_lr"
      },
      "outputs": [],
      "source": [
        "tp=\"Genre Classification Dataset/train_data.txt\"\n",
        "train=pd.read_csv(tp,sep=':::',names=['ID','TITLE','GENRE','DESCRIPTION'],engine='python')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GakP6h1ZYs8X"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO77voZ5f3-G"
      },
      "outputs": [],
      "source": [
        "train.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvJrSiG5cAE9"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLjtWO1yZdpz"
      },
      "outputs": [],
      "source": [
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yPY0ZvIZl72"
      },
      "outputs": [],
      "source": [
        "tep=\"Genre Classification Dataset/test_data.txt\"\n",
        "test=pd.read_csv(tep,sep=\":::\",names=['id','TITLE','DESCRIPTION'],engine='python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weesxWZeZ3AK"
      },
      "outputs": [],
      "source": [
        "test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggyOU9VFaS8m"
      },
      "outputs": [],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44L4XG25adgq"
      },
      "outputs": [],
      "source": [
        "test.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmtzJJ-6ag5T"
      },
      "outputs": [],
      "source": [
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7HX3u52akyE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,10))\n",
        "sns.countplot(data=train,x='GENRE',order=train['GENRE'].value_counts().index)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aAtDQGxZlLI"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAVGC3tqmtGp"
      },
      "outputs": [],
      "source": [
        "\n",
        "stemmer=LancasterStemmer()\n",
        "nltk.download('stopwords')\n",
        "stop_words=set(stopwords.words(\"english\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX5a4gEydo6d"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))  # Stopwords set\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@\\S+', '', text)  # replace twitter accounts with a space\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'.pic\\S+', '', text)\n",
        "    text = re.sub(r'#','',text)\n",
        "    text = re.sub(r'[^a-zA-Z+]', ' ', text)  # Change to replace non-characters with a space\n",
        "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
        "    words = nltk.word_tokenize(text)\n",
        "    # Use the predefined stop_words variable instead of redefining it inside the function\n",
        "    text = \" \".join([i for i in words if i not in stop_words and len(i) > 2])\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Replace multiple spaces with a single space\n",
        "    return text\n",
        "\n",
        "train[\"TextCleaning\"] = train[\"DESCRIPTION\"].apply(clean_text)\n",
        "test[\"TextCleaning\"] = test[\"DESCRIPTION\"].apply(clean_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbOWAcn9ZfYM"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B26I0E9jVRgY"
      },
      "outputs": [],
      "source": [
        "st = PorterStemmer()\n",
        "train['TextCleaning'] = train['TextCleaning'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "test['TextCleaning'] = test['TextCleaning'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd-ZGaiLqNG9"
      },
      "outputs": [],
      "source": [
        "train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twSo0-UXecJZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train['GENRE'] = le.fit_transform(train['GENRE'].values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyrN7PeefV09"
      },
      "outputs": [],
      "source": [
        "# keep only relevent columns\n",
        "train_df = train.loc[:,['TextCleaning', 'GENRE']]\n",
        "test_df = test.loc[:,['TextCleaning', 'TITLE']]\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zhBv8x9jz2m"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(train_df['TextCleaning'] ,train['GENRE'] , test_size=0.2 , shuffle=True , random_state = 42)\n",
        "print(f'Split data into train and eval sets')\n",
        "print(f'Traning Set\\t: {len(X_train)}\\nValidation Set\\t: {len(X_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRbCh-cmvuua"
      },
      "outputs": [],
      "source": [
        "vectorize = TfidfVectorizer(stop_words='english', max_features=100000)\n",
        "\n",
        "X_train_tfidf = vectorize.fit_transform(X_train)\n",
        "\n",
        "X_test_tfidf = vectorize.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EZOOrNhojnD"
      },
      "outputs": [],
      "source": [
        "lr_model=LogisticRegression()\n",
        "lr_model.fit(X_train_tfidf,y_train)\n",
        "predict_lr=lr_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, predict_lr))\n",
        "lr_accuracy = accuracy_score(y_test, predict_lr)\n",
        "print('Logistic Regression accuracy is: {:.2f}%'.format(lr_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL_3UjgdNQ2v"
      },
      "outputs": [],
      "source": [
        "sv_model=SVC()\n",
        "sv_model.fit(X_train_tfidf,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIG6yWHzL6Qp"
      },
      "outputs": [],
      "source": [
        "predict_sv=sv_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, predict_sv))\n",
        "sv_accuracy = accuracy_score(y_test,predict_sv)\n",
        "print('Support vector accuracy is: {:.2f}%'.format(sv_accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCNwKr-qFGbz"
      },
      "outputs": [],
      "source": [
        "nv_model=MultinomialNB()\n",
        "nv_model.fit(X_train_tfidf,y_train)\n",
        "predict_nv=nv_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, predict_nv))\n",
        "nv_accuracy = accuracy_score(y_test,predict_nv)\n",
        "print('Navie bayes accuracy is: {:.2f}%'.format(nv_accuracy*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11vBdlCxs31lwbDOjPpUeKS7_XWUCGQWg",
      "authorship_tag": "ABX9TyOSDkE8ZRN0XzxiDIatQAVH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}